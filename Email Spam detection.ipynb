{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam detection with Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam =pd.read_csv('messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content - length : 4437 call for papers is the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m . a . in scandinavian linguistics</td>\n",
       "      <td>m . a . in scandinavian linguistics at the uni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>call for papers : linguistics session of the m...</td>\n",
       "      <td>call for papers linguistics session - - midwes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>foreign language in commercials</td>\n",
       "      <td>content - length : 1937 greetings ! i ' m wond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fulbright announcement : please post / dissemi...</td>\n",
       "      <td>fulbright announcement : please post / dissemi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gala ' 95 : call for papers</td>\n",
       "      <td>groningen assembly on language acquisition 199...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bu conf on language development ' 95 - announc...</td>\n",
       "      <td>20th annual boston university conference on la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>korean software for macintosh</td>\n",
       "      <td>dear sir / madam , would you please send me an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>syntax the antisymmetry of syntax richard s . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simultaneous prepositions and postpositions in...</td>\n",
       "      <td>i ' m looking for analyses of nominal construc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sum : imperatives without you subjects</td>\n",
       "      <td>content - length : 3573 summary of responses t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>policies</td>\n",
       "      <td>moderators ' message a very happy 1995 to all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>* * * correction to hellenistic greek announce...</td>\n",
       "      <td>a couple of days ago i send an fyi on hellenis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>question on audio samples</td>\n",
       "      <td>i am looking for audio samples of english spee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sexism and language</td>\n",
       "      <td>re lydie e . meunier 's latest , i did not mea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>teaching english in korea</td>\n",
       "      <td>teaching english in korea the language center ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>free</td>\n",
       "      <td>this is a multi-part message in mime format . ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>email address for w . dressler</td>\n",
       "      <td>colleagues - we are trying to contact wolfgang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dhumbadji ! , journal for the history of language</td>\n",
       "      <td>good news for all subscribers , the december i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>question : quantitative information</td>\n",
       "      <td>hello , there is someone who knows where can i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>re : amharic</td>\n",
       "      <td>i am doing independent study on the rift valle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>uniformitarianism</td>\n",
       "      <td>in response to the request for info on this to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>re : 6 . 1094 , qs : phonemicity of writing</td>\n",
       "      <td>this is stimulated by richard sproat 's query ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>intensive summer arabic language institute</td>\n",
       "      <td>the georgetown arabic department of the school...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lists on comparative literature</td>\n",
       "      <td>content - length : 616 i . m new at this list ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>summary : even if</td>\n",
       "      <td>dear linguists , on linguist list : vol . 8-95...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>content - length : 1653 i , too , had noted th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>q : incorporation in mandarin ?</td>\n",
       "      <td>having recently arrived in taiwan to take up a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>wholesale club !</td>\n",
       "      <td>hi , we where wondering if you would be intere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>re : call me now 732-942 - 7100</td>\n",
       "      <td>hi sexy : i am considered one of the hottest p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>http : / / www . xxxnet . cx</td>\n",
       "      <td>the most nasty , raunchy adult interactive web...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>summary of responses to query on tok masta ( f...</td>\n",
       "      <td>almost two months ago i posted the following q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>this is new on 95 . 8 capital fm</td>\n",
       "      <td>to unsubscribe from these e-mails go to http :...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>sum : verbal humour</td>\n",
       "      <td>content - length : 4144 dear linguist readers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>subcategorization in tranformational grammar</td>\n",
       "      <td>dear colleagues , i ' m wondering if someone c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>parsers for russian</td>\n",
       "      <td>this query was also posted to seelangs - - apo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>case studies needed</td>\n",
       "      <td>dear colleagues , i ' m preparing to teach an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>re : 8 . 1107 , qs : lang . games , \" democrat...</td>\n",
       "      <td>dear mr . ungar : is us congress incorrect ? a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>indoeuropean courses listed by universities ( ...</td>\n",
       "      <td>the titus project &amp; the indogermanische gesell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>job : indonesian / asian studies</td>\n",
       "      <td>lecturer ( indonesian / asian studies ) ( ref ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>critics of manaster ramer miss the main point ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>summary : heavy onsets references</td>\n",
       "      <td>original query :\\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>sum master 's dissertation</td>\n",
       "      <td>dear netters , about a week ago i asked for he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>internships in israel</td>\n",
       "      <td>i have recently moved to israel and am studyin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>accept credit cards and watch sales skyrocket !</td>\n",
       "      <td>increase online sales up to 200 % http : / / 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>evolvable hardware and gp</td>\n",
       "      <td>paper now available in post script . . . \" rap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>did that work for you ? - calsvxtn</td>\n",
       "      <td>hello thanks for stopping by ! ! we have taken...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>british vs . american &lt; a &gt; ( s</td>\n",
       "      <td>griffin bacal internet mail direct inquiries t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>from fanny , recommending nek</td>\n",
       "      <td>dear sir or madam , this is not a \" spam \" mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>win $ 300usd and a cruise !</td>\n",
       "      <td>raquel 's casino , inc . is awarding a cruise ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>love your profile - ysuolvpv</td>\n",
       "      <td>hello thanks for stopping by ! ! we have taken...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>you have been asked to join kiddin</td>\n",
       "      <td>the list owner of : \" kiddin \" has invited you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>anglicization of composers ' names</td>\n",
       "      <td>judging from the return post , i must have sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>gotcha ! there are two separate fallacies in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>re : american - english in australia</td>\n",
       "      <td>hello ! i ' m working on a thesis concerning a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "0               job posting - apple-iss research center   \n",
       "1                                                   NaN   \n",
       "2     query : letter frequencies for text identifica...   \n",
       "3                                                  risk   \n",
       "4                              request book information   \n",
       "5     call for abstracts : optimality in syntactic t...   \n",
       "6                   m . a . in scandinavian linguistics   \n",
       "7     call for papers : linguistics session of the m...   \n",
       "8                       foreign language in commercials   \n",
       "9     fulbright announcement : please post / dissemi...   \n",
       "10                          gala ' 95 : call for papers   \n",
       "11    bu conf on language development ' 95 - announc...   \n",
       "12                        korean software for macintosh   \n",
       "13                                                  NaN   \n",
       "14    simultaneous prepositions and postpositions in...   \n",
       "15               sum : imperatives without you subjects   \n",
       "16                                             policies   \n",
       "17    * * * correction to hellenistic greek announce...   \n",
       "18                            question on audio samples   \n",
       "19                                  sexism and language   \n",
       "20                            teaching english in korea   \n",
       "21                                                 free   \n",
       "22                       email address for w . dressler   \n",
       "23    dhumbadji ! , journal for the history of language   \n",
       "24                  question : quantitative information   \n",
       "25                                         re : amharic   \n",
       "26                                    uniformitarianism   \n",
       "27          re : 6 . 1094 , qs : phonemicity of writing   \n",
       "28           intensive summer arabic language institute   \n",
       "29                      lists on comparative literature   \n",
       "...                                                 ...   \n",
       "2863                                  summary : even if   \n",
       "2864  re : 6 . 797 , comparative method : n - ary co...   \n",
       "2865                    q : incorporation in mandarin ?   \n",
       "2866                                   wholesale club !   \n",
       "2867                    re : call me now 732-942 - 7100   \n",
       "2868                       http : / / www . xxxnet . cx   \n",
       "2869  summary of responses to query on tok masta ( f...   \n",
       "2870                   this is new on 95 . 8 capital fm   \n",
       "2871                                sum : verbal humour   \n",
       "2872       subcategorization in tranformational grammar   \n",
       "2873                                parsers for russian   \n",
       "2874                                case studies needed   \n",
       "2875  re : 8 . 1107 , qs : lang . games , \" democrat...   \n",
       "2876  indoeuropean courses listed by universities ( ...   \n",
       "2877                   job : indonesian / asian studies   \n",
       "2878  re : 6 . 797 , comparative method : n - ary co...   \n",
       "2879                  summary : heavy onsets references   \n",
       "2880                         sum master 's dissertation   \n",
       "2881                              internships in israel   \n",
       "2882    accept credit cards and watch sales skyrocket !   \n",
       "2883                          evolvable hardware and gp   \n",
       "2884                 did that work for you ? - calsvxtn   \n",
       "2885                    british vs . american < a > ( s   \n",
       "2886                      from fanny , recommending nek   \n",
       "2887                        win $ 300usd and a cruise !   \n",
       "2888                       love your profile - ysuolvpv   \n",
       "2889                 you have been asked to join kiddin   \n",
       "2890                 anglicization of composers ' names   \n",
       "2891  re : 6 . 797 , comparative method : n - ary co...   \n",
       "2892               re : american - english in australia   \n",
       "\n",
       "                                                message  label  \n",
       "0     content - length : 3386 apple-iss research cen...      0  \n",
       "1     lang classification grimes , joseph e . and ba...      0  \n",
       "2     i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3     a colleague and i are researching the differin...      0  \n",
       "4     earlier this morning i was on the phone with a...      0  \n",
       "5     content - length : 4437 call for papers is the...      0  \n",
       "6     m . a . in scandinavian linguistics at the uni...      0  \n",
       "7     call for papers linguistics session - - midwes...      0  \n",
       "8     content - length : 1937 greetings ! i ' m wond...      0  \n",
       "9     fulbright announcement : please post / dissemi...      0  \n",
       "10    groningen assembly on language acquisition 199...      0  \n",
       "11    20th annual boston university conference on la...      0  \n",
       "12    dear sir / madam , would you please send me an...      0  \n",
       "13    syntax the antisymmetry of syntax richard s . ...      0  \n",
       "14    i ' m looking for analyses of nominal construc...      0  \n",
       "15    content - length : 3573 summary of responses t...      0  \n",
       "16    moderators ' message a very happy 1995 to all ...      0  \n",
       "17    a couple of days ago i send an fyi on hellenis...      0  \n",
       "18    i am looking for audio samples of english spee...      0  \n",
       "19    re lydie e . meunier 's latest , i did not mea...      0  \n",
       "20    teaching english in korea the language center ...      0  \n",
       "21    this is a multi-part message in mime format . ...      1  \n",
       "22    colleagues - we are trying to contact wolfgang...      0  \n",
       "23    good news for all subscribers , the december i...      0  \n",
       "24    hello , there is someone who knows where can i...      0  \n",
       "25    i am doing independent study on the rift valle...      0  \n",
       "26    in response to the request for info on this to...      0  \n",
       "27    this is stimulated by richard sproat 's query ...      0  \n",
       "28    the georgetown arabic department of the school...      0  \n",
       "29    content - length : 616 i . m new at this list ...      0  \n",
       "...                                                 ...    ...  \n",
       "2863  dear linguists , on linguist list : vol . 8-95...      0  \n",
       "2864  content - length : 1653 i , too , had noted th...      0  \n",
       "2865  having recently arrived in taiwan to take up a...      0  \n",
       "2866  hi , we where wondering if you would be intere...      1  \n",
       "2867  hi sexy : i am considered one of the hottest p...      1  \n",
       "2868  the most nasty , raunchy adult interactive web...      1  \n",
       "2869  almost two months ago i posted the following q...      0  \n",
       "2870  to unsubscribe from these e-mails go to http :...      1  \n",
       "2871  content - length : 4144 dear linguist readers ...      0  \n",
       "2872  dear colleagues , i ' m wondering if someone c...      0  \n",
       "2873  this query was also posted to seelangs - - apo...      0  \n",
       "2874  dear colleagues , i ' m preparing to teach an ...      0  \n",
       "2875  dear mr . ungar : is us congress incorrect ? a...      0  \n",
       "2876  the titus project & the indogermanische gesell...      0  \n",
       "2877  lecturer ( indonesian / asian studies ) ( ref ...      0  \n",
       "2878  critics of manaster ramer miss the main point ...      0  \n",
       "2879                               original query :\\r\\n      0  \n",
       "2880  dear netters , about a week ago i asked for he...      0  \n",
       "2881  i have recently moved to israel and am studyin...      0  \n",
       "2882  increase online sales up to 200 % http : / / 3...      1  \n",
       "2883  paper now available in post script . . . \" rap...      0  \n",
       "2884  hello thanks for stopping by ! ! we have taken...      1  \n",
       "2885  griffin bacal internet mail direct inquiries t...      0  \n",
       "2886  dear sir or madam , this is not a \" spam \" mes...      1  \n",
       "2887  raquel 's casino , inc . is awarding a cruise ...      1  \n",
       "2888  hello thanks for stopping by ! ! we have taken...      1  \n",
       "2889  the list owner of : \" kiddin \" has invited you...      1  \n",
       "2890  judging from the return post , i must have sou...      0  \n",
       "2891  gotcha ! there are two separate fallacies in t...      0  \n",
       "2892  hello ! i ' m working on a thesis concerning a...      0  \n",
       "\n",
       "[2893 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0            job posting - apple-iss research center   \n",
       "1                                                NaN   \n",
       "2  query : letter frequencies for text identifica...   \n",
       "3                                               risk   \n",
       "4                           request book information   \n",
       "\n",
       "                                             message  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  lang classification grimes , joseph e . and ba...      0  \n",
       "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3  a colleague and i are researching the differin...      0  \n",
       "4  earlier this morning i was on the phone with a...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2893, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'message', 'label'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the columns names\n",
    "spam.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the duplicates\n",
    "spam.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2876, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show new shape(New number of row and columns)\n",
    "spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    62\n",
       "message     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the number of missing data (Nan,NAN,na) data for each column\n",
    "spam.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw that in subject there is 62 missing vaalues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use fillna to fill missing values in subject column\n",
    "spam['subject'].fillna('Missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    0\n",
       "message    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the missing values again\n",
    "spam.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there is no missing values in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets download stopwords for the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\my\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the model\n",
    "def process_text(message):\n",
    "    #1 remove punctuatuation\n",
    "    #2 remove stopwords\n",
    "    #3 return a list of clean text\n",
    "    \n",
    "    #1\n",
    "    nopunc =[char for char in message if char not in string.punctuation]\n",
    "    nopunc=''.join(nopunc)\n",
    "    \n",
    "    #2\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    #3\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use tokenization in NLP process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [content, length, 3386, appleiss, research, ce...\n",
       "1    [lang, classification, grimes, joseph, e, barb...\n",
       "2    [posting, inquiry, sergei, atamas, satamas, um...\n",
       "3    [colleague, researching, differing, degrees, r...\n",
       "4    [earlier, morning, phone, friend, mine, living...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the tokenization ( a list tokens also called lemmas)\n",
    "spam['message'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a collection of text to a matrix of tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a collection of text to a matrix of tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "messages_bow = CountVectorizer(analyzer=process_text).fit_transform(spam['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now lets do train test splitting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(messages_bow,spam['label'],test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2876, 64661)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the shape messages_bow\n",
    "messages_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create and train naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#lets print the predictions\n",
    "print(classifier.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Print actual values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1914\n",
      "           1       0.99      0.99      0.99       386\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2300\n",
      "   macro avg       0.99      1.00      1.00      2300\n",
      "weighted avg       1.00      1.00      1.00      2300\n",
      "\n",
      "\n",
      "confusion matrix :\n",
      " [[1910    4]\n",
      " [   2  384]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the gtraing data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred =classifier.predict(X_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print()\n",
    "print('confusion matrix :\\n',confusion_matrix(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1914\n",
      "           1       0.99      0.99      0.99       386\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2300\n",
      "   macro avg       0.99      1.00      1.00      2300\n",
      "weighted avg       1.00      1.00      1.00      2300\n",
      "\n",
      "\n",
      "confusion matrix :\n",
      " [[1910    4]\n",
      " [   2  384]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the gtraing data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred =classifier.predict(X_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print()\n",
    "print('confusion matrix :\\n',confusion_matrix(y_train,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1914\n",
      "           1       0.99      0.99      0.99       386\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2300\n",
      "   macro avg       0.99      1.00      1.00      2300\n",
      "weighted avg       1.00      1.00      1.00      2300\n",
      "\n",
      "\n",
      "confusion matrix :\n",
      " [[1910    4]\n",
      " [   2  384]]\n",
      "\n",
      "Accuracy:  0.9973913043478261\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the gtraing data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred =classifier.predict(X_train)\n",
    "print(classification_report(y_train,pred))\n",
    "print()\n",
    "print('confusion matrix :\\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ',accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#lets print the predictions\n",
    "print(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#print the actual value\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       494\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       576\n",
      "   macro avg       0.97      0.99      0.98       576\n",
      "weighted avg       0.99      0.99      0.99       576\n",
      "\n",
      "\n",
      "confusion matrix :\n",
      " [[488   6]\n",
      " [  0  82]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the gtraing data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred =classifier.predict(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "print()\n",
    "print('confusion matrix :\\n',confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       494\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       576\n",
      "   macro avg       0.97      0.99      0.98       576\n",
      "weighted avg       0.99      0.99      0.99       576\n",
      "\n",
      "\n",
      "confusion matrix :\n",
      " [[488   6]\n",
      " [  0  82]]\n",
      "\n",
      "Accuracy:  0.9895833333333334\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the gtraing data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "pred =classifier.predict(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "print()\n",
    "print('confusion matrix :\\n',confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on test data is 98% so the model is very fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
